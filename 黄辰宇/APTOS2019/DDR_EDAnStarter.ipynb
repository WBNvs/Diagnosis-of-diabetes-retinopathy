{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "389ed66e-c650-435f-bca7-3961f7cf0dcc",
   "metadata": {},
   "source": [
    "# APTOS_DDR_EDAnStarter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850e8d6e-4423-4a4d-be40-611fa31103f8",
   "metadata": {},
   "source": [
    "**Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2308e65c-f777-498e-a9b8-a2b18e06e3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matlotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cb7c89-02d2-49e6-86c6-13ad950d43a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d00ade2-6080-4ce2-843e-66d0684fd360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making pretrained weights work without needing to find the default filename\n",
    "if not os.path.exists('/tmp/.cache/torch/checkpoints/'):\n",
    "        os.makedirs('/tmp/.cache/torch/checkpoints/')\n",
    "!cp '/resnet50.pth' '/tmp/.cache/torch/checkpoints/resnet50-19c8e357.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ce8480-de4e-44c0-862f-1a9b8e1a670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Make sure cudnn is enabled:', torch.backends.cudnn.enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9185e38d-34a7-43f2-a959-b1e877f53912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 999\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77650ad9-f916-4b99-a367-08c78a90dfcc",
   "metadata": {},
   "source": [
    "**Reading data and Basic EDA**\n",
    "Open the dataset with pandas, check distribution of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3ab334-4fc3-40ef-8db9-a7b827e9653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_image_dir = '/autodl-tmp/DDR/'\n",
    "train_dir = os.path.join(base_image_dir,'train_images/')\n",
    "df = pd.read_csv(os.path.join(base_image_dir, 'train.csv'))\n",
    "df['path'] = df['id_code'].map(lambda x: os.path.join(train_dir,'{}.png'.format(x)))\n",
    "df = df.drop(columns=['id_code'])\n",
    "df = df.sample(frac=1).reset_index(drop=True) # shuffle dataframe\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd1c08e-b342-46ba-84d9-fd7a72a48dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_df = len(df)\n",
    "print(f\"There are {len_df} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a05760-7bf2-49d5-bb05-318a9a10bfe5",
   "metadata": {},
   "source": [
    "This is actually very **small**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf0e1ae-ddb2-468e-8df3-a83c64f71b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'].hist(figsize = (10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1bf5b4-281f-423a-a463-6b675657eea4",
   "metadata": {},
   "source": [
    "The dataset is highly **imbalanced**, with many samples for level 0, and very little for the rest of the levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a08306-d2a2-41f7-ad94-4a9dabc8f525",
   "metadata": {},
   "source": [
    "Let's look at an example image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74273a04-4363-4d24-8d38-9581d7b1141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "im = Image.open(df['path'][1])\n",
    "width, height = im.size\n",
    "print(width,height) \n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa8f95b-14ee-4927-bc68-936b57e61fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.asarray(im))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac94ab4-99af-4a30-bfca-34fae66e8081",
   "metadata": {},
   "source": [
    "The images are quite big. We will resize to a much smaller size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d895a181-7419-4e6a-9004-dd0b53a43e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64 # smaller batch size is better for training, but may take longer\n",
    "sz=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbd7a75-adb2-4d0d-b31d-907807afcf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(do_flip=True,flip_vert=True,max_rotate=360,max_warp=0,max_zoom=1.1,max_lighting=0.1,p_lighting=0.5)\n",
    "src = (ImageList.from_df(df=df,path='./',cols='path') # get dataset from dataset\n",
    "        .split_by_rand_pct(0.2) # Splitting the dataset\n",
    "        .label_from_df(cols='diagnosis',label_cls=FloatList) # obtain labels from the level column\n",
    "      )\n",
    "data= (src.transform(tfms,size=sz,resize_method=ResizeMethod.SQUISH,padding_mode='zeros') # Data augmentation\n",
    "        .databunch(bs=bs,num_workers=4) # DataBunch\n",
    "        .normalize(imagenet_stats) # Normalize     \n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff06d49-d5f2-4ba2-ba7f-cba541ff726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=3, figsize=(7,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bfcbdc-f0e4-4741-bb74-3a844fd415ba",
   "metadata": {},
   "source": [
    "**Training (Transfer learning)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4afe550-b069-407f-bf66-f3eecf6ea84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "def quadratic_kappa(y_hat, y):\n",
    "    return torch.tensor(cohen_kappa_score(torch.round(y_hat), y, weights='quadratic'),device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cb83a0-d9c9-4759-b9d8-11a0c5e7fbc5",
   "metadata": {},
   "source": [
    "**Training**\n",
    "We use *transfer learning*, where we retrain the last layers of a pretrained neural network. We use the *ResNet50* architecture trained on the *ImageNet* dataset, which has been commonly used for pre-training applications in computer vision. *Fastai* makes it quite simple to create a model and train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343e84b7-1ad5-47ef-a1cc-3c9833317765",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, base_arch=models.resnet50, metrics = [quadratic_kappa])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856652bc-7f1d-4467-b247-354b8ca9ca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b202eb5d-3e9d-4237-9926-3bddf39b1f72",
   "metadata": {},
   "source": [
    "Here we can see that the loss decreases fastest around lr=1e-2 so that is what we will use to train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b390f434-3f58-4726-b204-37e7a8ce0c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(4,max_lr = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159973fa-b8f4-4a4c-91be-1a18d9bd4c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()\n",
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a66928f-387b-4ee4-81db-8e80f07c6679",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cdaa79-b08d-4d8e-ba08-e24c09d368c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(6, max_lr=slice(1e-6,1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b7a614-2859-43f6-9c11-b32da4d165fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()\n",
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051dd744-4022-45ff-bf86-a9ea71cd662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export()\n",
    "learn.save('stage-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8c70a3-139e-4b6c-b68a-673a0c16c21a",
   "metadata": {},
   "source": [
    "**Evaluate the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c0fe68-923d-43ce-a04d-8cdd6240bd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "\n",
    "losses,idxs = interp.top_losses()\n",
    "\n",
    "len(data.valid_ds)==len(losses)==len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a76d86c-4ef1-47cb-ab02-a5aac62cacc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(figsize=(12,12), dpi=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f3c9da-75b4-4480-9c50-74698e911760",
   "metadata": {},
   "source": [
    "**Optimize the Metric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc31bf64-737d-4115-a17f-02f9fc2f8cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds = learn.get_preds(ds_type=DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687b0dfa-8fc0-4141-966a-a88aa51eb038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy as sp\n",
    "from functools import partial\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2922b61-1775-4966-a6e7-29a43475cb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "\n",
    "        ll = metrics.cohen_kappa_score(y, X_p, weights='quadratic')\n",
    "        return -ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5, 3.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "        print(-loss_partial(self.coef_['x']))\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a49c734-c3de-4b58-8dc7-0331acc4223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optR = OptimizedRounder()\n",
    "optR.fit(valid_preds[0],valid_preds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47696908-9cdf-4137-8ff0-de4ad69c8cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = optR.coefficients()\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495b1922-e62e-4abf-b8ac-905a11cb7d09",
   "metadata": {},
   "source": [
    "**TTA**\n",
    "Test-time augmentation, or TTA, is a commonly-used technique to provide a boost in your score, and is very simple to implement. Fastai already has TTA implemented, but it is not the best for all purposes, so we're redefining the fastai function and using my custom version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d909d65-d83a-4be2-a9c3-27c948d26ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.core import *\n",
    "from fastai.basic_data import *\n",
    "from fastai.basic_train import *\n",
    "from fastai.torch_core import *\n",
    "def _tta_only(learn:Learner, ds_type:DatasetType=DatasetType.Valid, num_pred:int=10) -> Iterator[List[Tensor]]:\n",
    "    \"Computes the outputs for several augmented inputs for TTA\"\n",
    "    dl = learn.dl(ds_type)\n",
    "    ds = dl.dataset\n",
    "    old = ds.tfms\n",
    "    aug_tfms = [o for o in learn.data.train_ds.tfms]\n",
    "    try:\n",
    "        pbar = master_bar(range(num_pred))\n",
    "        for i in pbar:\n",
    "            ds.tfms = aug_tfms\n",
    "            yield get_preds(learn.model, dl, pbar=pbar)[0]\n",
    "    finally: ds.tfms = old\n",
    "\n",
    "Learner.tta_only = _tta_only\n",
    "\n",
    "def _TTA(learn:Learner, beta:float=0, ds_type:DatasetType=DatasetType.Valid, num_pred:int=10, with_loss:bool=False) -> Tensors:\n",
    "    \"Applies TTA to predict on `ds_type` dataset.\"\n",
    "    preds,y = learn.get_preds(ds_type)\n",
    "    all_preds = list(learn.tta_only(ds_type=ds_type, num_pred=num_pred))\n",
    "    avg_preds = torch.stack(all_preds).mean(0)\n",
    "    if beta is None: return preds,avg_preds,y\n",
    "    else:            \n",
    "        final_preds = preds*beta + avg_preds*(1-beta)\n",
    "        if with_loss: \n",
    "            with NoneReduceOnCPU(learn.loss_func) as lf: loss = lf(final_preds, y)\n",
    "            return final_preds, y, loss\n",
    "        return final_preds, y\n",
    "\n",
    "Learner.TTA = _TTA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f5d9e2-d562-4f34-999b-89d42030dfd8",
   "metadata": {},
   "source": [
    "**Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58217c2f-5478-47f0-9cae-8e270be0d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv('/autodl-tmp/DDR/sample_submission.csv')\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d7f18-c92f-4f83-b316-81645ef49058",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.add_test(ImageList.from_df(sample_df,'/autodl-tmp/DDR',folder='test_images',suffix='.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5887482e-1ddc-42d0-a335-4650b0dbcb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,y = learn.TTA(ds_type=DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492826f7-e5b7-4ccf-a924-f9a568e6fadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = optR.predict(preds, coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf826cd-5658-4b0e-932e-16b919c90ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.diagnosis = test_predictions.astype(int)\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d722c90-f420-4f54-8b56-fd1be5af3260",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
